{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "A common problem is that powerful models can perfectly fit the data on which they are trained. These models are often <b>low bias</b> and <b>high variance</b> However, we can't observe the variance of a model directly, because we only know how it fits the data we have rather than all potential samples. The goal of supervised learning and the models which we will learn about is to build a model that generalizes. It should accurately predict the future rather than the past.\n",
    "\n",
    "<b>Solution:</b> Use a procedure that <b>estimates</b> how well a model is likely to perform on out-of-sample data and use that to choose between models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset import\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Decision tree based imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# For train test split and cross validation \n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "The Iris dataset is one of datasets scikit-learn comes with that do not require the downloading of any file from some external website. The code below loads the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and y variable to stores the feature matrix and target from the Iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['sepal length (cm)',\n",
    "        'sepal width (cm)',\n",
    "        'petal length (cm)',\n",
    "        'petal width (cm)']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Train and Test on the Entire Data Set (Do Not Do This)\n",
    "This is what we have been doing so far in this class for convenience, but it is a bad practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Train the model on the **entire data set**.\n",
    "2. Test the model on the **same data set** and evaluate how well we did by comparing the **predicted** response values with the **true** response values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model you want to use\n",
    "# We already did this at top of page, but repeating in case you wonder where this code comes from\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Make an instance of the model\n",
    "clf = DecisionTreeClassifier(max_depth = 5, \n",
    "                             random_state = 0)\n",
    "\n",
    "# Train the model on the data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# class predictions \n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure Model Performance\n",
    "\n",
    "While there are other ways of measuring model performance (precision, recall, F1 Score, [ROC Curve](https://towardsdatascience.com/receiver-operating-characteristic-curves-demystified-in-python-bd531a4364d0), etc), we are going to keep this simple for now and use accuracy as our metric.Â \n",
    "To do this are going to see how the model performs on new data (test set)\n",
    "\n",
    "Accuracy is defined as:\n",
    "(fraction of correct predictions): correct predictions / total number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# calculate classification accuracy\n",
    "score = clf.score(X, y)\n",
    "print('Accuracy Score: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems With Training and Testing on the Same Data\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**.\n",
    "- Maximizing the training accuracy rewards **overly complex models** that won't necessarily generalize.\n",
    "- Unnecessarily complex models **overfit** the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overfitting](images/overfitting.png)\n",
    "\n",
    "*Image Credit: [Overfitting](http://commons.wikimedia.org/wiki/File:Overfitting.svg#/media/File:Overfitting.svg) by Chabacano. Licensed under GFDL via Wikimedia Commons.\n",
    "\n",
    "*Idea Credit: [@justmarkham](https://twitter.com/justmarkham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split (What we will mostly do in this class)\n",
    "\n",
    "1. Split the data set into two pieces: a **training set** and a **testing set**.\n",
    "2. Train the model on the **training set**.\n",
    "3. Test the model on the **testing set** and evaluate how well we did.\n",
    "\n",
    "What does this accomplish?\n",
    "\n",
    "- Models can be trained and tested on **different data** (We treat testing data like out-of-sample data).\n",
    "- Response values are known for the testing set and thus **predictions can be evaluated**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undering train_test_split in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int or RandomState instance, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Understanding the `random_state` Parameter\n",
    "\n",
    "The `random_state` is a pseudo-random number that allows us to reproduce our results every time we run them. However, it makes it impossible to predict what are exact results will be if we chose a new `random_state`.\n",
    "\n",
    "`random_state` is very useful for testing that your model was made correctly since it provides you with the same split each time. However, make sure you remove it if you are testing for model variability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below makes roughly 80% (this could change for future version of scikit-learn) of the data into a training set and the remaining into a testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train_test_split](images/trainTestSplit.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state = 0,\n",
    "                                                    test_size =.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original features matrix\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original target vector\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model you want to use\n",
    "# We already did this at top of page, but repeating in case you wonder where this code comes from\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Make an instance of the model\n",
    "clf = DecisionTreeClassifier(max_depth = 3, \n",
    "                             random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# class predictions for the test set\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure Model Performance\n",
    "\n",
    "While there are other ways of measuring model performance (precision, recall, F1 Score, [ROC Curve](https://towardsdatascience.com/receiver-operating-characteristic-curves-demystified-in-python-bd531a4364d0), etc), we are going to keep this simple for now and use accuracy as our metric.Â \n",
    "To do this are going to see how the model performs on new data (test set)\n",
    "\n",
    "Accuracy is defined as:\n",
    "(fraction of correct predictions): correct predictions / total number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# calculate classification accuracy\n",
    "score = clf.score(X_test, y_test)\n",
    "print('Accuracy Score: {0}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Advantages of Train/Test Split</b>: Fast, simple, computationally inexpensive.\n",
    "\n",
    "<b>Disadvantages of Train/Test Split</b>: Eliminates data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for cell from Introduction to Machine Learning with Python \n",
    "# by Andreas Muller & Sarah Guido pg 258\n",
    "# https://github.com/amueller/mglearn/blob/master/mglearn/plot_cross_validation.py\n",
    "\n",
    "def plot_cross_validation():\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    plt.title(\"cross_validation\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_frame_on(False)\n",
    "\n",
    "    n_folds = 5\n",
    "    n_samples = 25\n",
    "\n",
    "    n_samples_per_fold = n_samples / float(n_folds)\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        colors = [\"w\"] * n_folds\n",
    "        colors[i] = \"grey\"\n",
    "        bars = plt.barh(\n",
    "            y=range(n_folds), width=[n_samples_per_fold - 0.1] * n_folds,\n",
    "            left=i * n_samples_per_fold, height=.6, color=colors, hatch=\"//\",\n",
    "            edgecolor='k', align='edge')\n",
    "    axes.invert_yaxis()\n",
    "    axes.set_xlim(0, n_samples + 1)\n",
    "    plt.ylabel(\"CV iterations\")\n",
    "    plt.xlabel(\"Data points\")\n",
    "    plt.xticks(np.arange(n_samples_per_fold / 2., n_samples,\n",
    "                         n_samples_per_fold),\n",
    "               [\"Fold %d\" % x for x in range(1, n_folds + 1)])\n",
    "    plt.yticks(np.arange(n_folds) + .3,\n",
    "               [\"Split %d\" % x for x in range(1, n_folds + 1)])\n",
    "    plt.legend([bars[0], bars[4]], ['Training data', 'Test data'],\n",
    "               loc=(1.05, 0.4), frameon=False)\n",
    "    \n",
    "    \n",
    "plot_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above is 5 fold cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train/test split is useful, but it's a shame that we aren't using more data for training. \n",
    "\n",
    "**How can we use the maximum amount of our data points while still ensuring model integrity?**\n",
    "\n",
    "1. Split the dataset into K equal partitions (or \"folds\")\n",
    "    * So if k = 5 and dataset has 150 observations\n",
    "    * Each of the 5 folds would have 30 observations\n",
    "2. Use fold 1 as the testing set and rest is a training set\n",
    "    * Testing set = 30 observations (fold 5)\n",
    "    * Training set = 120 observations (fold 1-4)\n",
    "3. Calculate testing accuracy\n",
    "4. Repeat step 2 and step 3 K times, using a different fold as the testing set each time.\n",
    "    * 2nd iteration\n",
    "        * fold 4 would be the testing set\n",
    "        * combination of fold 1, 2, 3, and 5 would be the training set\n",
    "    * 3rd iteration\n",
    "        * fold 3 would be the testing set\n",
    "        * combination of fold 1, 2, 4, and 5 would be the training set\n",
    "    * 4th iteration\n",
    "        * fold 2 would be the testing set\n",
    "        * combination of fold 1, 3, 4, and 5 would be the training set\n",
    "    * 5th iteration\n",
    "        * fold 1 would be the testing set\n",
    "        * combination of fold 2, 3, 4, and 5 would be the training set\n",
    "5. Average all test accuracies to get the estimated out-of-sample accuracy.\n",
    "\n",
    "Although this may sound complicated, we are just training the model on k separate train-test-splits, then taking an average of the resulting test accuracies. This is more computationally intensive than train test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/cross_validation_diagram.png)\n",
    "\n",
    "There are many different variations of this procedure that we aren't covering in this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making this process similar to the image in the previous section\n",
    "kf = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "n= 0\n",
    "print(\"~~~~ CROSS VALIDATION each fold ~~~~\")\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    clf = DecisionTreeClassifier().fit(X[train_index], y[train_index])\n",
    "    score = clf.score(X[test_index], y[test_index])\n",
    "\n",
    "    accuracy_list.append(score)\n",
    "    print('Model: ', n+1)\n",
    "    print('Accuracy: ', accuracy_list[n])\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean of Accuracy for all folds:', np.mean(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# cross-validatation using a method (very similar to what we did in the code above)\n",
    "cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is different each time because the sampling is different each time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing cross-validation to train/test split\n",
    "Advantages of **cross-validation:**\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "Advantages of **train/test split:**\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
